%%% SURVEY

@article{ROB-021,
url = {http://dx.doi.org/10.1561/2300000021},
year = {2013},
volume = {2},
journal = {Foundations and Trends in Robotics},
title = {A Survey on Policy Search for Robotics},
doi = {10.1561/2300000021},
issn = {1935-8253},
number = {1â€“2},
pages = {1-142},
author = {Marc Peter Deisenroth and Gerhard Neumann and Jan Peters}
}

%%% Articles cited in survey

% Finite Difference Methods
@inproceedings{Peters:2006fk,
  added-at = {2008-03-10T10:19:21.000+0100},
  address = {Beijing, China},
  author = {Peters, J. and Schaal, S.},
  biburl = {http://www.bibsonomy.org/bibtex/232ec379c1f59b22bb350bea0c09da1c8/janrpeters},
  booktitle = {{Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}},
  date-added = {2006-10-25 20:11:50 -0700},
  date-modified = {2007-04-24 16:08:54 +0200},
  interhash = {9c7b45c7618d5ad49475e9ebd3c1453c},
  intrahash = {32ec379c1f59b22bb350bea0c09da1c8},
  keywords = {gradients imitation learning, learning,reinforcement motor policy primitives, reinforcement robotics,},
  local-url = {http://www-clmc.usc.edu/publications/P/Peters_IROS_2006.pdf},
  timestamp = {2008-03-10T10:22:52.000+0100},
  title = {{Policy gradient methods for robotics}},
  year = 2006
}

@inproceedings{stoneICRA04,
  author = {Kohl, Nate   and Stone, Peter  },
  booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation},
  citeulike-article-id = {2514742},
  keywords = {bibtex-import, daanbib},
  month = {May},
  priority = {2},
  title = {Policy Gradient Reinforcement Learning for Fast Quadrupedal Locomotion},
  year = {2004}
}

% REINFORCE algorithm
@article{Williams:92,
  author = {Williams, R. J. },
  citeulike-article-id = {2514734},
  journal = {Machine Learning},
  keywords = {bibtex-import, daanbib},
  pages = {229--256},
  priority = {2},
  title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  volume = {8},
  year = {1992}
}

% Policy gradient algorithms' issues
@article{kober_MACH_2011,
  author =     "Kober, J. and  Peters, J.",
  year =     "2011",
  title =    "Policy Search for Motor Primitives in Robotics",
  booktitle =    "Machine Learning",
  URL =      "http://www.ias.informatik.tu-darmstadt.de/uploads/Publications/kober_MACH_2011.pdf",
  number =     "1-2",
  pages =    "171-203",
}

% Original EM algorithm
@article{neal1998vaj,
    title = "{A view of the EM algorithm that justifies incremental, sparse, and other variants}",
    author = "Neal, R.M. and Hinton, G.E.",
    journal = "Learning in graphical models",
    volume = "89",
    pages = "355--368",
    year = "1998",
    url = "http://www.cs.toronto.edu/~radford/ftp/emk.pdf",
}

% Variational methods for PS
@inproceedings{neumann_icml2011,
  author =     "Neumann, G.",
  year =     "2011",
  title =    "Variational Inference for Policy Search in Changing Situations",
  booktitle =    "Proceedings of the International Conference on Machine Learning (ICML 2011) ",
  URL =      "http://www.ias.informatik.tu-darmstadt.de/uploads/Site/EditPublication/neumann_icml2011.pdf",
}

% Monte Carlo for PS
@inproceedings{Peters_PESANN_2007,
  author =     "Peters, J. and  Schaal, S.",
  year =     "2007",
  title =    "Applying the episodic natural actor-critic architecture to motor primitive learning",
  booktitle =    "Proceedings of the 2007 European Symposium on Artificial Neural Networks (ESANN)",
  key =      "reinforcement learning, policy gradient methods, motor primitives, natural actor-critic",
  URL =      "http://www-clmc.usc.edu/publications//P/peters-ESANN2007.pdf",
}

% Natural policy gradient
@article{4867,
  title = {Reinforcement Learning of Motor Skills with Policy Gradients},
  author = {Peters, J. and Schaal, S.},
  journal = {Neural Networks},
  volume = {21},
  number = {4},
  pages = {682-697},
  organization = {Max-Planck-Gesellschaft},
  school = {Biologische Kybernetik},
  month = may,
  year = {2008}
}

% REPS
@InProceedings{Peters+MA:2010,
  author =       "Peters, Jan and  M{\"u}lling, Katharina and Alt{\"u}n, Yasemin",
  title =        "Relative Entropy Policy Search",
  booktitle =    "Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence (AAAI 2010)",
  year =         "2010",
  editor =    "Fox, Maria and Poole, David",
  publisher = "AAAI Press",
  pages =     "1607--1612",
  url = "http://kyb.mpg.de/fileadmin/user_upload/files/publications/attachments/AAAI-2010-Peters_6439%5B0%5D.pdf",
  bib2html_rescat = "Learning Methods",
}

% GPS

@inproceedings{2013-gps,
    author = {Sergey Levine and Vladlen Koltun},
    title = {Guided Policy Search},
    booktitle = {ICML '13: Proceedings of the 30th International Conference on Machine Learning},
    year = {2013},
}

@incollection{NIPS2014_5444,
title = {Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics},
author = {Levine, Sergey and Abbeel, Pieter},
booktitle = {Advances in Neural Information Processing Systems 27},
editor = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
pages = {1071--1079},
year = {2014},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5444-learning-neural-network-policies-with-guided-policy-search-under-unknown-dynamics.pdf}
}